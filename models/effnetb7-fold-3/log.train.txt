
--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **

--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **

--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **
	initial_checkpoint = None

optimizer
  AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 5e-05
    maximize: False
    weight_decay: 0.01
)

** start training here! **
   batch_size = 8 
                     |-------------- VALID---------|---- TRAIN/BATCH ----------------
rate     iter  epoch | dice   loss   tp     tn     | loss           | time           
-------------------------------------------------------------------------------------
0.00e+0   00000000*   0.00 | 0.099  0.715   | 0.000   | 60.77312350273132

--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **
** start training here! **
   batch_size = 8 
                     |-------------- VALID---------|---- TRAIN/BATCH ----------------
rate     iter  epoch | dice   loss   tp     tn     | loss           | time           
-------------------------------------------------------------------------------------

--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **
	initial_checkpoint = None

optimizer
  AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 5e-05
    maximize: False
    weight_decay: 0.01
)

** start training here! **
   batch_size = 8 
                     |-------------- VALID---------|---- TRAIN/BATCH ----------------
rate     iter  epoch | dice   loss   tp     tn     | loss           | time           
-------------------------------------------------------------------------------------
0.00e+0   00000000*   0.00 | 0.196  1.164   | 0.000   | 33.89580678939819

--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **
	initial_checkpoint = None

optimizer
  AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 5e-05
    maximize: False
    weight_decay: 0.01
)

** start training here! **
   batch_size = 8 
                     |-------------- VALID---------|---- TRAIN/BATCH ----------------
rate     iter  epoch | dice   loss   tp     tn     | loss           | time           
-------------------------------------------------------------------------------------

--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **
	initial_checkpoint = None

optimizer
  AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 5e-05
    maximize: False
    weight_decay: 0.01
)

** start training here! **
   batch_size = 8 
                     |-------------- VALID---------|---- TRAIN/BATCH ----------------
rate     iter  epoch | dice   loss   tp     tn     | loss           | time           
-------------------------------------------------------------------------------------

--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **
	initial_checkpoint = None

optimizer
  AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 5e-05
    maximize: False
    weight_decay: 0.01
)

** start training here! **
   batch_size = 8 
                     |-------------- VALID---------|---- TRAIN/BATCH ----------------
rate     iter  epoch | dice   loss   tp     tn     | loss           | time           
-------------------------------------------------------------------------------------

--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **
	initial_checkpoint = None

optimizer
  AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 5e-05
    maximize: False
    weight_decay: 0.01
)

** start training here! **
   batch_size = 8 
                     |-------------- VALID---------|---- TRAIN/BATCH ----------------
rate     iter  epoch | dice   loss   tp     tn     | loss           | time           
-------------------------------------------------------------------------------------
0.00e+0   00000000*   0.00 | 0.176  1.652   | 0.000   | 8.40519666671753
5.00e-5   00000099*   3.00 | 0.177  0.264   | 0.323   | 81.89390397071838
5.00e-5   00000198*   6.00 | 0.221  0.198   | 0.243   | 128.05231547355652
5.00e-5   00000297*   9.00 | 0.317  0.179   | 0.222   | 174.17886924743652
5.00e-5   00000396*  12.00 | 0.459  0.171   | 0.196   | 220.36454319953918
5.00e-5   00000495*  15.00 | 0.527  0.163   | 0.199   | 266.6188414096832
5.00e-5   00000594*  18.00 | 0.540  0.157   | 0.171   | 312.7878065109253
5.00e-5   00000693*  21.00 | 0.523  0.149   | 0.177   | 359.31481742858887
5.00e-5   00000792*  24.00 | 0.554  0.143   | 0.159   | 405.998064994812
5.00e-5   00000891*  27.00 | 0.587  0.149   | 0.151   | 452.4916591644287
5.00e-5   00000990*  30.00 | 0.588  0.137   | 0.149   | 499.39667654037476
5.00e-5   00001089*  33.00 | 0.598  0.137   | 0.150   | 545.6127035617828
5.00e-5   00001188*  36.00 | 0.610  0.132   | 0.137   | 591.6408314704895
5.00e-5   00001287*  39.00 | 0.617  0.148   | 0.131   | 638.0248656272888
5.00e-5   00001386*  42.00 | 0.626  0.133   | 0.133   | 684.7186017036438
5.00e-5   00001485*  45.00 | 0.634  0.134   | 0.122   | 730.9584596157074
5.00e-5   00001584*  48.00 | 0.644  0.126   | 0.121   | 777.1438200473785
5.00e-5   00001683*  51.00 | 0.653  0.123   | 0.108   | 823.3684959411621
5.00e-5   00001782*  54.00 | 0.645  0.122   | 0.118   | 870.9860947132111
5.00e-5   00001881*  57.00 | 0.656  0.125   | 0.113   | 918.601969242096
5.00e-5   00001980*  60.00 | 0.662  0.121   | 0.111   | 965.632910490036
5.00e-5   00002079*  63.00 | 0.659  0.121   | 0.107   | 1012.6779658794403
5.00e-5   00002178*  66.00 | 0.665  0.122   | 0.097   | 1059.3019931316376
5.00e-5   00002277*  69.00 | 0.669  0.119   | 0.100   | 1106.0549771785736
5.00e-5   00002376*  72.00 | 0.668  0.117   | 0.093   | 1153.3673930168152
5.00e-5   00002475*  75.00 | 0.674  0.127   | 0.101   | 1200.5031230449677
5.00e-5   00002574*  78.00 | 0.669  0.116   | 0.093   | 1248.2912983894348
5.00e-5   00002673*  81.00 | 0.680  0.116   | 0.090   | 1297.7827501296997
5.00e-5   00002772*  84.00 | 0.688  0.120   | 0.086   | 1347.3642477989197
5.00e-5   00002871*  87.00 | 0.689  0.112   | 0.088   | 1396.7412972450256
5.00e-5   00002970*  90.00 | 0.695  0.116   | 0.089   | 1446.0278255939484
5.00e-5   00003069*  93.00 | 0.695  0.109   | 0.088   | 1493.2636234760284
5.00e-5   00003168*  96.00 | 0.696  0.119   | 0.082   | 1540.3747856616974
5.00e-5   00003267*  99.00 | 0.691  0.109   | 0.081   | 1587.2165899276733
5.00e-5   00003366* 102.00 | 0.677  0.111   | 0.082   | 1634.0884687900543
5.00e-5   00003465* 105.00 | 0.703  0.121   | 0.079   | 1681.0294981002808
5.00e-5   00003564* 108.00 | 0.697  0.117   | 0.078   | 1728.051041841507
5.00e-5   00003663* 111.00 | 0.702  0.117   | 0.076   | 1775.215045452118
5.00e-5   00003762* 114.00 | 0.692  0.118   | 0.075   | 1822.2936482429504
5.00e-5   00003861* 117.00 | 0.704  0.120   | 0.073   | 1870.0362231731415
5.00e-5   00003960* 120.00 | 0.704  0.116   | 0.079   | 1918.2093901634216
5.00e-5   00004059* 123.00 | 0.698  0.113   | 0.074   | 1965.6848862171173
5.00e-5   00004158* 126.00 | 0.703  0.115   | 0.078   | 2013.3496038913727
5.00e-5   00004257* 129.00 | 0.703  0.119   | 0.070   | 2061.5996379852295
5.00e-5   00004356* 132.00 | 0.694  0.113   | 0.072   | 2109.096747636795
5.00e-5   00004455* 135.00 | 0.706  0.109   | 0.070   | 2156.6224377155304
5.00e-5   00004554* 138.00 | 0.705  0.114   | 0.067   | 2204.3028593063354
5.00e-5   00004653* 141.00 | 0.702  0.121   | 0.067   | 2252.424486398697
5.00e-5   00004752* 144.00 | 0.715  0.114   | 0.072   | 2300.800441265106
5.00e-5   00004851* 147.00 | 0.706  0.109   | 0.070   | 2349.331549167633
5.00e-5   00004950* 150.00 | 0.711  0.111   | 0.066   | 2397.584498167038
5.00e-5   00005049* 153.00 | 0.713  0.116   | 0.066   | 2445.6131398677826
5.00e-5   00005148* 156.00 | 0.696  0.111   | 0.068   | 2494.5005252361298
5.00e-5   00005247* 159.00 | 0.707  0.117   | 0.065   | 2542.703385591507
5.00e-5   00005346* 162.00 | 0.695  0.113   | 0.064   | 2590.8790850639343
5.00e-5   00005445* 165.00 | 0.704  0.111   | 0.066   | 2638.84557056427
5.00e-5   00005544* 168.00 | 0.714  0.115   | 0.063   | 2687.618451833725
5.00e-5   00005643* 171.00 | 0.711  0.112   | 0.068   | 2737.490613222122
5.00e-5   00005742* 174.00 | 0.711  0.114   | 0.064   | 2786.4853839874268
5.00e-5   00005841* 177.00 | 0.716  0.116   | 0.066   | 2835.7565512657166
5.00e-5   00005940* 180.00 | 0.712  0.116   | 0.062   | 2883.6630115509033
5.00e-5   00006039* 183.00 | 0.710  0.122   | 0.063   | 2930.7540504932404
5.00e-5   00006138* 186.00 | 0.708  0.118   | 0.062   | 2978.5080831050873
5.00e-5   00006237* 189.00 | 0.719  0.117   | 0.057   | 3026.7119901180267
5.00e-5   00006336* 192.00 | 0.706  0.114   | 0.059   | 3075.331251144409
5.00e-5   00006435* 195.00 | 0.711  0.118   | 0.063   | 3123.7408690452576
5.00e-5   00006534* 198.00 | 0.715  0.124   | 0.057   | 3176.6204533576965
5.00e-5   00006633* 201.00 | 0.717  0.118   | 0.061   | 3224.534811973572
5.00e-5   00006732* 204.00 | 0.708  0.116   | 0.060   | 3272.840659379959
5.00e-5   00006831* 207.00 | 0.713  0.123   | 0.056   | 3320.317816734314
5.00e-5   00006930* 210.00 | 0.717  0.116   | 0.058   | 3367.8767907619476
5.00e-5   00007029* 213.00 | 0.714  0.112   | 0.059   | 3415.9951384067535
5.00e-5   00007128* 216.00 | 0.714  0.114   | 0.058   | 3466.312148332596
5.00e-5   00007227* 219.00 | 0.721  0.118   | 0.058   | 3514.4968276023865
5.00e-5   00007326* 222.00 | 0.721  0.113   | 0.056   | 3562.9832775592804
5.00e-5   00007425* 225.00 | 0.719  0.117   | 0.056   | 3610.820043325424
5.00e-5   00007524* 228.00 | 0.713  0.117   | 0.057   | 3658.731215953827
5.00e-5   00007623* 231.00 | 0.721  0.118   | 0.057   | 3712.4438972473145
5.00e-5   00007722* 234.00 | 0.721  0.121   | 0.059   | 3761.004108428955
5.00e-5   00007821* 237.00 | 0.703  0.125   | 0.053   | 3808.733083486557
5.00e-5   00007920* 240.00 | 0.704  0.124   | 0.054   | 3857.9988882541656
5.00e-5   00008019* 243.00 | 0.713  0.129   | 0.055   | 3907.6641323566437
5.00e-5   00008118* 246.00 | 0.712  0.119   | 0.055   | 3957.1649050712585
5.00e-5   00008217* 249.00 | 0.708  0.119   | 0.053   | 4005.926270723343
5.00e-5   00008316* 252.00 | 0.717  0.115   | 0.055   | 4055.1869695186615
5.00e-5   00008415* 255.00 | 0.723  0.124   | 0.055   | 4103.780661821365
5.00e-5   00008514* 258.00 | 0.714  0.125   | 0.053   | 4152.109631061554
5.00e-5   00008613* 261.00 | 0.710  0.121   | 0.051   | 4200.085159301758
5.00e-5   00008712* 264.00 | 0.713  0.129   | 0.052   | 4248.2818558216095
5.00e-5   00008811* 267.00 | 0.707  0.130   | 0.050   | 4297.487962007523
5.00e-5   00008910* 270.00 | 0.709  0.121   | 0.052   | 4350.661228895187


--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **
	initial_checkpoint = None

optimizer
  AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 5e-05
    maximize: False
    weight_decay: 0.01
)

** start training here! **
   batch_size = 8 
                     |-------------- VALID ---------|---- TRAIN/BATCH ----------------
rate     iter  epoch | dice   loss   tp     tn     | loss           | time           
-------------------------------------------------------------------------------------
0.00e+0   00000000*   0.00 | 0.170  1.323   | 0.000   | 10.69111180305481

--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **

--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **
	initial_checkpoint = None

optimizer
  AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 5e-05
    maximize: False
    weight_decay: 0.01
)

** start training here! **
   batch_size = 8 
                     |-------------- VALID ---------|---- TRAIN/BATCH ----------------
rate     iter  epoch | dice   loss   tp     tn     | loss           | time           
-------------------------------------------------------------------------------------
0.00e+0   00000000*   0.00 | 0.095  0.820   | 0.000   | 7.292378664016724

--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **

--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **
	initial_checkpoint = None

optimizer
  AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 5e-05
    maximize: False
    weight_decay: 0.01
)

** start training here! **
   batch_size = 8 
                     |-------------- VALID ---------|---- TRAIN/BATCH ----------------
rate     iter  epoch | dice   loss   tp     tn     | loss           | time           
-------------------------------------------------------------------------------------
0.00e+0   00000000*   0.00 | 0.065  0.708   | 0.000   | 6.030450820922852

--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **

--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **
	initial_checkpoint = None

optimizer
  AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 5e-05
    maximize: False
    weight_decay: 0.01
)

** start training here! **
   batch_size = 8 
                     |-------------- VALID ---------|---- TRAIN/BATCH ----------------
rate     iter  epoch | dice   loss   tp     tn     | loss           | time           
-------------------------------------------------------------------------------------
0.00e+0   00000000*   0.00 | 0.001  0.467   | 0.000   | 7.237210273742676
5.00e-5   00000198*   3.00 | 0.001  0.248   | 0.088   | 103.12199902534485
5.00e-5   00000396*   6.00 | 0.527  0.264   | 0.064   | 199.48300623893738
5.00e-5   00000594*   9.00 | 0.538  0.171   | 0.051   | 297.0153534412384
5.00e-5   00000792*  12.00 | 0.588  0.152   | 0.047   | 394.7004141807556
5.00e-5   00000990*  15.00 | 0.596  0.137   | 0.046   | 491.98237657546997
5.00e-5   00001188*  18.00 | 0.641  0.138   | 0.043   | 589.3567531108856
5.00e-5   00001386*  21.00 | 0.656  0.142   | 0.040   | 686.8025708198547
5.00e-5   00001584*  24.00 | 0.657  0.135   | 0.036   | 783.9952373504639
5.00e-5   00001782*  27.00 | 0.672  0.131   | 0.038   | 881.7532861232758
5.00e-5   00001980*  30.00 | 0.669  0.115   | 0.033   | 978.8592751026154
5.00e-5   00002178*  33.00 | 0.674  0.114   | 0.032   | 1075.4440121650696
5.00e-5   00002376*  36.00 | 0.679  0.113   | 0.033   | 1172.8801617622375
5.00e-5   00002574*  39.00 | 0.686  0.116   | 0.029   | 1270.255867242813
5.00e-5   00002772*  42.00 | 0.698  0.111   | 0.029   | 1367.7460284233093
5.00e-5   00002970*  45.00 | 0.694  0.109   | 0.026   | 1466.0746939182281
5.00e-5   00003168*  48.00 | 0.686  0.110   | 0.026   | 1563.8610067367554
5.00e-5   00003366*  51.00 | 0.700  0.105   | 0.025   | 1662.486317396164
5.00e-5   00003564*  54.00 | 0.697  0.102   | 0.022   | 1761.493346452713
5.00e-5   00003762*  57.00 | 0.709  0.108   | 0.022   | 1859.8697805404663
5.00e-5   00003960*  60.00 | 0.708  0.105   | 0.022   | 1957.6068665981293
5.00e-5   00004158*  63.00 | 0.704  0.105   | 0.021   | 2054.4029319286346
5.00e-5   00004356*  66.00 | 0.719  0.108   | 0.019   | 2150.3999197483063
5.00e-5   00004554*  69.00 | 0.713  0.103   | 0.019   | 2247.7144107818604
5.00e-5   00004752*  72.00 | 0.704  0.107   | 0.021   | 2344.55543756485
5.00e-5   00004950*  75.00 | 0.726  0.112   | 0.019   | 2440.485184907913
5.00e-5   00005148*  78.00 | 0.723  0.101   | 0.020   | 2537.835036277771
5.00e-5   00005346*  81.00 | 0.715  0.101   | 0.017   | 2626.5346767902374
5.00e-5   00005544*  84.00 | 0.722  0.103   | 0.017   | 2716.713377714157
5.00e-5   00005742*  87.00 | 0.723  0.102   | 0.016   | 2805.5003855228424
5.00e-5   00005940*  90.00 | 0.716  0.096   | 0.017   | 2895.0093162059784
5.00e-5   00006138*  93.00 | 0.711  0.110   | 0.018   | 2983.859723806381
5.00e-5   00006336*  96.00 | 0.725  0.101   | 0.016   | 3073.513745069504
5.00e-5   00006534*  99.00 | 0.723  0.097   | 0.016   | 3163.0733408927917
5.00e-5   00006732* 102.00 | 0.735  0.100   | 0.016   | 3252.698342561722
5.00e-5   00006930* 105.00 | 0.728  0.100   | 0.015   | 3342.300106525421
5.00e-5   00007128* 108.00 | 0.729  0.095   | 0.015   | 3435.8405458927155
5.00e-5   00007326* 111.00 | 0.733  0.100   | 0.016   | 3524.7280926704407
5.00e-5   00007524* 114.00 | 0.725  0.103   | 0.015   | 3614.281885623932
5.00e-5   00007722* 117.00 | 0.728  0.094   | 0.014   | 3703.784883737564
5.00e-5   00007920* 120.00 | 0.701  0.107   | 0.014   | 3792.4367520809174
5.00e-5   00008118* 123.00 | 0.718  0.097   | 0.014   | 3881.81258893013
5.00e-5   00008316* 126.00 | 0.734  0.095   | 0.014   | 3970.627952814102
5.00e-5   00008514* 129.00 | 0.711  0.104   | 0.014   | 4060.208370447159
5.00e-5   00008712* 132.00 | 0.733  0.096   | 0.016   | 4149.022060632706
5.00e-5   00008910* 135.00 | 0.738  0.101   | 0.014   | 4238.533229112625


--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **
	initial_checkpoint = None

optimizer
  AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 5e-05
    maximize: False
    weight_decay: 0.01
)

** start training here! **
   batch_size = 8 
                     |-------------- VALID ---------|---- TRAIN/BATCH ----------------
rate     iter  epoch | dice   loss   tp     tn     | loss           | time           
-------------------------------------------------------------------------------------
0.00e+0   00000000*   0.00 | 0.000  0.436   | 0.000   | 39.46455979347229
5.00e-5   00000198*   3.00 | 0.201  0.219   | 0.082   | 173.08790183067322
5.00e-5   00000396*   6.00 | 0.417  0.186   | 0.061   | 269.4988603591919
5.00e-5   00000594*   9.00 | 0.566  0.176   | 0.054   | 366.47304129600525
5.00e-5   00000792*  12.00 | 0.588  0.163   | 0.051   | 461.3909206390381
5.00e-5   00000990*  15.00 | 0.612  0.168   | 0.043   | 558.6308720111847
5.00e-5   00001188*  18.00 | 0.614  0.142   | 0.042   | 653.8954930305481
5.00e-5   00001386*  21.00 | 0.635  0.143   | 0.043   | 751.0527536869049
5.00e-5   00001584*  24.00 | 0.631  0.130   | 0.038   | 846.4149625301361
5.00e-5   00001782*  27.00 | 0.655  0.123   | 0.036   | 943.6196277141571
5.00e-5   00001980*  30.00 | 0.662  0.121   | 0.032   | 1039.1685736179352
5.00e-5   00002178*  33.00 | 0.670  0.116   | 0.032   | 1134.724847793579
5.00e-5   00002376*  36.00 | 0.663  0.112   | 0.032   | 1230.2607522010803
5.00e-5   00002574*  39.00 | 0.650  0.107   | 0.030   | 1327.6980617046356
5.00e-5   00002772*  42.00 | 0.682  0.116   | 0.029   | 1423.291479587555
5.00e-5   00002970*  45.00 | 0.685  0.104   | 0.027   | 1520.1851665973663
5.00e-5   00003168*  48.00 | 0.686  0.103   | 0.025   | 1614.6213643550873
5.00e-5   00003366*  51.00 | 0.690  0.100   | 0.027   | 1712.9705557823181
5.00e-5   00003564*  54.00 | 0.700  0.099   | 0.025   | 1806.24294424057
5.00e-5   00003762*  57.00 | 0.703  0.098   | 0.024   | 1902.7980568408966
5.00e-5   00003960*  60.00 | 0.703  0.097   | 0.024   | 2003.1277515888214
5.00e-5   00004158*  63.00 | 0.707  0.098   | 0.021   | 2102.0073285102844
5.00e-5   00004356*  66.00 | 0.715  0.095   | 0.022   | 2201.3252584934235
5.00e-5   00004554*  69.00 | 0.710  0.095   | 0.021   | 2296.838271856308
5.00e-5   00004752*  72.00 | 0.727  0.098   | 0.019   | 2392.618021965027
5.00e-5   00004950*  75.00 | 0.718  0.098   | 0.021   | 2487.456374168396
5.00e-5   00005148*  78.00 | 0.730  0.098   | 0.018   | 2585.47798538208
5.00e-5   00005346*  81.00 | 0.723  0.095   | 0.019   | 2683.7731218338013
5.00e-5   00005544*  84.00 | 0.721  0.093   | 0.018   | 2780.9826085567474
5.00e-5   00005742*  87.00 | 0.729  0.097   | 0.018   | 2884.8828163146973
5.00e-5   00005940*  90.00 | 0.723  0.094   | 0.017   | 2982.850453853607
5.00e-5   00006138*  93.00 | 0.729  0.094   | 0.018   | 3080.0538051128387
5.00e-5   00006336*  96.00 | 0.724  0.093   | 0.017   | 3177.7563016414642
5.00e-5   00006534*  99.00 | 0.727  0.097   | 0.017   | 3274.6615319252014
5.00e-5   00006732* 102.00 | 0.727  0.099   | 0.017   | 3372.7950263023376
5.00e-5   00006930* 105.00 | 0.722  0.092   | 0.016   | 3468.752900123596
5.00e-5   00007128* 108.00 | 0.728  0.093   | 0.016   | 3566.573474884033
5.00e-5   00007326* 111.00 | 0.721  0.092   | 0.016   | 3664.3271017074585
5.00e-5   00007524* 114.00 | 0.723  0.092   | 0.016   | 3762.6783213615417
5.00e-5   00007722* 117.00 | 0.730  0.093   | 0.016   | 3858.4236567020416
5.00e-5   00007920* 120.00 | 0.698  0.094   | 0.015   | 3956.3595898151398
5.00e-5   00008118* 123.00 | 0.711  0.097   | 0.015   | 4052.257924079895
5.00e-5   00008316* 126.00 | 0.748  0.093   | 0.015   | 4149.970393419266
5.00e-5   00008514* 129.00 | 0.760  0.094   | 0.015   | 4248.431987285614
5.00e-5   00008712* 132.00 | 0.754  0.097   | 0.015   | 4347.328071594238
5.00e-5   00008910* 135.00 | 0.755  0.092   | 0.014   | 4444.353638410568


--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **
	initial_checkpoint = None

optimizer
  AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 5e-05
    maximize: False
    weight_decay: 0.01
)

** start training here! **
   batch_size = 8 
                     |-------------- VALID ---------|---- TRAIN/BATCH ----------------
rate     iter  epoch | dice   loss   tp     tn     | loss           | time           
-------------------------------------------------------------------------------------
0.00e+0   00000000*   0.00 | 0.000  0.493   | 0.000   | 7.216319799423218
5.00e-5   00000198*   3.00 | 0.188  0.227   | 0.078   | 101.99549722671509
5.00e-5   00000396*   6.00 | 0.511  0.240   | 0.059   | 191.29873037338257
5.00e-5   00000594*   9.00 | 0.540  0.174   | 0.053   | 280.1720714569092
5.00e-5   00000792*  12.00 | 0.593  0.171   | 0.046   | 369.2793552875519
5.00e-5   00000990*  15.00 | 0.606  0.152   | 0.045   | 457.66291189193726
5.00e-5   00001188*  18.00 | 0.595  0.137   | 0.043   | 547.0077240467072
5.00e-5   00001386*  21.00 | 0.633  0.146   | 0.040   | 636.3085851669312
5.00e-5   00001584*  24.00 | 0.639  0.134   | 0.040   | 725.6956107616425
5.00e-5   00001782*  27.00 | 0.650  0.131   | 0.035   | 815.3078155517578
5.00e-5   00001980*  30.00 | 0.660  0.133   | 0.036   | 905.6351144313812
5.00e-5   00002178*  33.00 | 0.652  0.118   | 0.033   | 997.3175759315491
5.00e-5   00002376*  36.00 | 0.664  0.118   | 0.035   | 1087.0168416500092
5.00e-5   00002574*  39.00 | 0.658  0.113   | 0.030   | 1176.698002576828
5.00e-5   00002772*  42.00 | 0.671  0.111   | 0.030   | 1265.43088722229
5.00e-5   00002970*  45.00 | 0.675  0.105   | 0.029   | 1355.09850025177
5.00e-5   00003168*  48.00 | 0.669  0.109   | 0.027   | 1444.1582725048065
5.00e-5   00003366*  51.00 | 0.680  0.103   | 0.026   | 1533.85840177536
5.00e-5   00003564*  54.00 | 0.686  0.103   | 0.024   | 1623.5559148788452
5.00e-5   00003762*  57.00 | 0.691  0.106   | 0.025   | 1713.3274698257446
5.00e-5   00003960*  60.00 | 0.683  0.101   | 0.024   | 1803.1273667812347
5.00e-5   00004158*  63.00 | 0.685  0.100   | 0.023   | 1892.7952711582184
5.00e-5   00004356*  66.00 | 0.691  0.106   | 0.022   | 1982.691509962082
5.00e-5   00004554*  69.00 | 0.701  0.100   | 0.022   | 2072.4245364665985
5.00e-5   00004752*  72.00 | 0.702  0.101   | 0.021   | 2162.1820867061615
5.00e-5   00004950*  75.00 | 0.709  0.102   | 0.020   | 2252.211179971695
5.00e-5   00005148*  78.00 | 0.712  0.096   | 0.019   | 2342.186459302902
5.00e-5   00005346*  81.00 | 0.711  0.098   | 0.020   | 2432.077061891556
5.00e-5   00005544*  84.00 | 0.699  0.100   | 0.019   | 2521.889034509659
5.00e-5   00005742*  87.00 | 0.719  0.102   | 0.018   | 2611.88050031662
5.00e-5   00005940*  90.00 | 0.719  0.102   | 0.019   | 2701.9578988552094
5.00e-5   00006138*  93.00 | 0.714  0.095   | 0.019   | 2791.6091282367706
5.00e-5   00006336*  96.00 | 0.720  0.098   | 0.017   | 2881.2324187755585
5.00e-5   00006534*  99.00 | 0.707  0.097   | 0.019   | 2970.9528348445892
5.00e-5   00006732* 102.00 | 0.705  0.095   | 0.017   | 3060.974324464798
5.00e-5   00006930* 105.00 | 0.720  0.093   | 0.016   | 3151.0552887916565
5.00e-5   00007128* 108.00 | 0.715  0.094   | 0.017   | 3241.0246284008026
5.00e-5   00007326* 111.00 | 0.712  0.097   | 0.016   | 3330.7868535518646
5.00e-5   00007524* 114.00 | 0.693  0.097   | 0.016   | 3420.953551054001
5.00e-5   00007722* 117.00 | 0.701  0.094   | 0.017   | 3510.636062860489
5.00e-5   00007920* 120.00 | 0.712  0.093   | 0.016   | 3600.455053806305
5.00e-5   00008118* 123.00 | 0.712  0.095   | 0.015   | 3690.335681438446
5.00e-5   00008316* 126.00 | 0.725  0.094   | 0.015   | 3780.103319644928
5.00e-5   00008514* 129.00 | 0.724  0.094   | 0.016   | 3870.0790781974792
5.00e-5   00008712* 132.00 | 0.731  0.102   | 0.014   | 3959.9644236564636
5.00e-5   00008910* 135.00 | 0.734  0.099   | 0.014   | 4049.6341891288757
5.00e-5   00009108* 138.00 | 0.737  0.099   | 0.014   | 4139.3842668533325
5.00e-5   00009306* 141.00 | 0.730  0.094   | 0.014   | 4229.078394651413
5.00e-5   00009504* 144.00 | 0.733  0.095   | 0.013   | 4318.923051595688
5.00e-5   00009702* 147.00 | 0.736  0.098   | 0.014   | 4408.816026687622
5.00e-5   00009900* 150.00 | 0.729  0.096   | 0.013   | 4498.858327627182
5.00e-5   00010098* 153.00 | 0.743  0.097   | 0.013   | 4588.8229467868805
5.00e-5   00010296* 156.00 | 0.734  0.099   | 0.013   | 4678.611567974091
5.00e-5   00010494* 159.00 | 0.738  0.094   | 0.014   | 4768.398214101791
5.00e-5   00010692* 162.00 | 0.736  0.099   | 0.014   | 4858.314792633057
5.00e-5   00010890* 165.00 | 0.739  0.100   | 0.013   | 4948.207968235016
5.00e-5   00011088* 168.00 | 0.739  0.101   | 0.013   | 5038.0006358623505
5.00e-5   00011286* 171.00 | 0.740  0.101   | 0.012   | 5128.180111646652
5.00e-5   00011484* 174.00 | 0.745  0.103   | 0.012   | 5218.27818608284
5.00e-5   00011682* 177.00 | 0.737  0.099   | 0.013   | 5308.041636705399
5.00e-5   00011880* 180.00 | 0.742  0.103   | 0.012   | 5397.755696773529


--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **
	initial_checkpoint = None

optimizer
  AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 5e-05
    maximize: False
    weight_decay: 0.01
)

** start training here! **
   batch_size = 8 
                     |-------------- VALID ---------|---- TRAIN/BATCH ----------------
rate     iter  epoch | dice   loss   tp     tn     | loss           | time           
-------------------------------------------------------------------------------------
0.00e+0   00000000*   0.00 | 0.181  1.639   | 0.000   | 38.925546646118164

--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **
	initial_checkpoint = None

optimizer
  AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 5e-05
    maximize: False
    weight_decay: 0.01
)

** start training here! **
   batch_size = 8 
                     |-------------- VALID ---------|---- TRAIN/BATCH ----------------
rate     iter  epoch | dice   loss   tp     tn     | loss           | time           
-------------------------------------------------------------------------------------
0.00e+0   00000000*   0.00 | 0.002  0.493   | 0.000   | 7.970314025878906
5.00e-5   00000396*   3.00 | 0.003  0.254   | 0.036   | 218.21586060523987
5.00e-5   00000792*   6.00 | 0.275  0.191   | 0.032   | 411.74982166290283
5.00e-5   00001188*   9.00 | 0.444  0.184   | 0.029   | 606.872442483902
5.00e-5   00001584*  12.00 | 0.473  0.179   | 0.027   | 806.637405872345
5.00e-5   00001980*  15.00 | 0.360  0.163   | 0.027   | 1005.2785220146179
5.00e-5   00002376*  18.00 | 0.559  0.220   | 0.024   | 1210.0110132694244
5.00e-5   00002772*  21.00 | 0.540  0.172   | 0.026   | 1407.4102563858032
5.00e-5   00003168*  24.00 | 0.553  0.159   | 0.024   | 1600.9285945892334
5.00e-5   00003564*  27.00 | 0.556  0.167   | 0.023   | 1794.8636524677277
5.00e-5   00003960*  30.00 | 0.574  0.164   | 0.025   | 1987.9665608406067
5.00e-5   00004356*  33.00 | 0.589  0.179   | 0.021   | 2181.8126096725464
5.00e-5   00004752*  36.00 | 0.555  0.141   | 0.021   | 2376.4098885059357
5.00e-5   00005148*  39.00 | 0.591  0.140   | 0.022   | 2569.4768195152283
5.00e-5   00005544*  42.00 | 0.607  0.163   | 0.020   | 2763.97221827507
5.00e-5   00005940*  45.00 | 0.566  0.137   | 0.021   | 2955.9697120189667
5.00e-5   00006336*  48.00 | 0.605  0.158   | 0.019   | 3148.9790227413177
5.00e-5   00006732*  51.00 | 0.597  0.140   | 0.019   | 3342.653165578842
5.00e-5   00007128*  54.00 | 0.609  0.164   | 0.019   | 3543.145447731018
5.00e-5   00007524*  57.00 | 0.612  0.145   | 0.019   | 3735.581166744232
5.00e-5   00007920*  60.00 | 0.604  0.142   | 0.020   | 3928.6343698501587
5.00e-5   00008316*  63.00 | 0.604  0.129   | 0.019   | 4121.5038912296295
5.00e-5   00008712*  66.00 | 0.625  0.138   | 0.018   | 4313.226706504822
5.00e-5   00009108*  69.00 | 0.625  0.152   | 0.017   | 4504.5798625946045
5.00e-5   00009504*  72.00 | 0.613  0.121   | 0.018   | 4698.696887731552
5.00e-5   00009900*  75.00 | 0.615  0.132   | 0.018   | 4891.066169977188
5.00e-5   00010296*  78.00 | 0.624  0.125   | 0.017   | 5081.92772936821
5.00e-5   00010692*  81.00 | 0.622  0.130   | 0.017   | 5272.17369890213
5.00e-5   00011088*  84.00 | 0.625  0.127   | 0.017   | 5458.3176391124725
5.00e-5   00011484*  87.00 | 0.634  0.119   | 0.018   | 5641.522878170013
5.00e-5   00011880*  90.00 | 0.623  0.119   | 0.017   | 5824.593600273132


--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **
	initial_checkpoint = None

optimizer
  AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 5e-05
    maximize: False
    weight_decay: 0.01
)

** start training here! **
   batch_size = 8 
                     |-------------- VALID ---------|---- TRAIN/BATCH ----------------
rate     iter  epoch | dice   loss   tp     tn     | loss           | time           
-------------------------------------------------------------------------------------
0.00e+0   00000000*   0.00 | 0.000  0.498   | 0.000   | 8.276601314544678
5.00e-5   00000396*   3.00 | 0.068  0.233   | 0.039   | 201.87732815742493

--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **
	initial_checkpoint = None

optimizer
  AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 5e-05
    maximize: False
    weight_decay: 0.01
)

** start training here! **
   batch_size = 8 
                     |-------------- VALID---------|---- TRAIN/BATCH ----------------
rate     iter  epoch | dice   loss   tp     tn     | loss           | time           
-------------------------------------------------------------------------------------
0.00e+0   00000000*   0.00 | 0.181  1.788   | 0.000   | 10.455572843551636

--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **
	initial_checkpoint = None

optimizer
  AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 5e-05
    maximize: False
    weight_decay: 0.01
)

** start training here! **
   batch_size = 4 
                     |-------------- VALID---------|---- TRAIN/BATCH ----------------
rate     iter  epoch | dice   loss   tp     tn     | loss           | time           
-------------------------------------------------------------------------------------
0.00e+0   00000000*   0.00 | 0.020  0.517   | 0.000   | 7.1442930698394775
5.00e-5   00000198*   3.00 | 0.100  0.225   | 0.083   | 103.84515333175659
5.00e-5   00000396*   6.00 | 0.487  0.195   | 0.060   | 202.2564034461975
5.00e-5   00000594*   9.00 | 0.530  0.167   | 0.055   | 303.3806896209717
5.00e-5   00000792*  12.00 | 0.499  0.145   | 0.046   | 402.41132402420044
5.00e-5   00000990*  15.00 | 0.580  0.140   | 0.045   | 500.9924085140228
5.00e-5   00001188*  18.00 | 0.618  0.142   | 0.042   | 599.6463701725006
5.00e-5   00001386*  21.00 | 0.629  0.129   | 0.040   | 697.703446149826
5.00e-5   00001584*  24.00 | 0.637  0.130   | 0.037   | 795.9868612289429
5.00e-5   00001782*  27.00 | 0.649  0.123   | 0.035   | 896.5210881233215
5.00e-5   00001980*  30.00 | 0.637  0.116   | 0.034   | 997.4554288387299
5.00e-5   00002178*  33.00 | 0.664  0.114   | 0.031   | 1095.3790075778961
5.00e-5   00002376*  36.00 | 0.672  0.111   | 0.031   | 1195.2113823890686
5.00e-5   00002574*  39.00 | 0.674  0.106   | 0.031   | 1294.8086540699005
5.00e-5   00002772*  42.00 | 0.664  0.103   | 0.029   | 1397.1437456607819
5.00e-5   00002970*  45.00 | 0.689  0.103   | 0.027   | 1496.4787826538086
5.00e-5   00003168*  48.00 | 0.689  0.102   | 0.026   | 1597.1508848667145
5.00e-5   00003366*  51.00 | 0.678  0.102   | 0.025   | 1693.0119032859802
5.00e-5   00003564*  54.00 | 0.688  0.097   | 0.024   | 1790.6779305934906
5.00e-5   00003762*  57.00 | 0.696  0.099   | 0.024   | 1886.5511150360107
5.00e-5   00003960*  60.00 | 0.707  0.103   | 0.024   | 1986.1674361228943
5.00e-5   00004158*  63.00 | 0.703  0.097   | 0.023   | 2090.9935495853424
5.00e-5   00004356*  66.00 | 0.712  0.099   | 0.021   | 2189.955680370331
5.00e-5   00004554*  69.00 | 0.710  0.100   | 0.021   | 2280.803980588913
5.00e-5   00004752*  72.00 | 0.711  0.095   | 0.021   | 2373.500692844391
5.00e-5   00004950*  75.00 | 0.714  0.095   | 0.021   | 2463.423469543457
5.00e-5   00005148*  78.00 | 0.711  0.093   | 0.020   | 2556.20338511467
5.00e-5   00005346*  81.00 | 0.712  0.092   | 0.019   | 2647.3825047016144
5.00e-5   00005544*  84.00 | 0.721  0.093   | 0.019   | 2742.4447705745697
5.00e-5   00005742*  87.00 | 0.725  0.092   | 0.019   | 2832.4001743793488
5.00e-5   00005940*  90.00 | 0.725  0.094   | 0.019   | 2931.276859998703
5.00e-5   00006138*  93.00 | 0.727  0.095   | 0.018   | 3021.1245489120483
5.00e-5   00006336*  96.00 | 0.727  0.092   | 0.017   | 3114.6640713214874
5.00e-5   00006534*  99.00 | 0.725  0.092   | 0.016   | 3205.0127034187317
5.00e-5   00006732* 102.00 | 0.731  0.093   | 0.017   | 3308.317636489868
5.00e-5   00006930* 105.00 | 0.730  0.094   | 0.018   | 3400.296041250229
5.00e-5   00007128* 108.00 | 0.735  0.092   | 0.017   | 3505.437361240387
5.00e-5   00007326* 111.00 | 0.741  0.092   | 0.015   | 3596.1376049518585
5.00e-5   00007524* 114.00 | 0.732  0.094   | 0.016   | 3701.582763671875
5.00e-5   00007722* 117.00 | 0.726  0.101   | 0.016   | 3798.116741657257
5.00e-5   00007920* 120.00 | 0.729  0.094   | 0.016   | 3897.9725732803345
5.00e-5   00008118* 123.00 | 0.738  0.094   | 0.016   | 3995.1292185783386
5.00e-5   00008316* 126.00 | 0.742  0.094   | 0.016   | 4094.2791328430176
5.00e-5   00008514* 129.00 | 0.739  0.094   | 0.014   | 4191.047427415848
5.00e-5   00008712* 132.00 | 0.744  0.097   | 0.015   | 4290.978759765625
5.00e-5   00008910* 135.00 | 0.738  0.095   | 0.015   | 4387.87285900116


--- [START EfficientNet-b7] ----------------------------------------------------------------


** dataset setting **
fold = 3
train_dataset : 
	len = 264
                  kidney  77 (0.292) 
                prostate  70 (0.265) 
          largeintestine  41 (0.155) 
                  spleen  38 (0.144) 
                    lung  38 (0.144) 

valid_dataset : 
	len = 87
                  kidney  22 (0.253) 
                prostate  23 (0.264) 
          largeintestine  17 (0.195) 
                  spleen  15 (0.172) 
                    lung  10 (0.115) 


** net setting **
	initial_checkpoint = None

optimizer
  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 5e-05
    maximize: False
    weight_decay: 1e-05
)

** start training here! **
   batch_size = 4 
                     |-------------- VALID---------|---- TRAIN/BATCH ----------------
rate     iter  epoch | dice   loss   tp     tn     | loss           | time           
-------------------------------------------------------------------------------------
0.00e+0   00000000*   0.00 | 0.171  1.368   | 0.000   | 7.279371738433838
5.00e-5   00000198*   3.00 | 0.001  0.276   | 0.096   | 106.87295818328857
5.00e-5   00000396*   6.00 | 0.386  0.185   | 0.061   | 209.81591629981995
5.00e-5   00000594*   9.00 | 0.532  0.171   | 0.053   | 303.0947678089142
5.00e-5   00000792*  12.00 | 0.372  0.158   | 0.049   | 399.29884338378906
5.00e-5   00000990*  15.00 | 0.556  0.141   | 0.044   | 495.23702692985535
5.00e-5   00001188*  18.00 | 0.571  0.135   | 0.043   | 589.2940545082092
5.00e-5   00001386*  21.00 | 0.617  0.138   | 0.044   | 685.8905000686646
5.00e-5   00001584*  24.00 | 0.608  0.128   | 0.039   | 781.949465751648
5.00e-5   00001782*  27.00 | 0.631  0.121   | 0.035   | 879.079422712326
5.00e-5   00001980*  30.00 | 0.660  0.126   | 0.033   | 972.3364453315735
5.00e-5   00002178*  33.00 | 0.660  0.123   | 0.033   | 1066.8338205814362
5.00e-5   00002376*  36.00 | 0.662  0.116   | 0.031   | 1161.0928902626038
5.00e-5   00002574*  39.00 | 0.672  0.112   | 0.033   | 1253.2163519859314
5.00e-5   00002772*  42.00 | 0.661  0.108   | 0.028   | 1345.0004081726074
5.00e-5   00002970*  45.00 | 0.673  0.114   | 0.028   | 1437.7585361003876
5.00e-5   00003168*  48.00 | 0.676  0.107   | 0.030   | 1534.8131568431854
5.00e-5   00003366*  51.00 | 0.651  0.108   | 0.027   | 1625.9580726623535
5.00e-5   00003564*  54.00 | 0.682  0.104   | 0.025   | 1719.4017615318298
5.00e-5   00003762*  57.00 | 0.681  0.105   | 0.025   | 1812.9979121685028
5.00e-5   00003960*  60.00 | 0.676  0.104   | 0.024   | 1910.4678802490234
5.00e-5   00004158*  63.00 | 0.687  0.105   | 0.023   | 2007.7647738456726
5.00e-5   00004356*  66.00 | 0.682  0.104   | 0.023   | 2104.648489713669
5.00e-5   00004554*  69.00 | 0.688  0.106   | 0.022   | 2202.0632417201996
5.00e-5   00004752*  72.00 | 0.694  0.104   | 0.022   | 2299.4048438072205
5.00e-5   00004950*  75.00 | 0.678  0.104   | 0.021   | 2396.3862211704254
5.00e-5   00005148*  78.00 | 0.700  0.100   | 0.019   | 2491.037732362747
5.00e-5   00005346*  81.00 | 0.698  0.101   | 0.020   | 2580.603338956833
5.00e-5   00005544*  84.00 | 0.703  0.099   | 0.019   | 2669.953995704651
5.00e-5   00005742*  87.00 | 0.707  0.102   | 0.019   | 2759.260010957718
5.00e-5   00005940*  90.00 | 0.707  0.103   | 0.020   | 2848.80127620697
5.00e-5   00006138*  93.00 | 0.713  0.098   | 0.017   | 2938.222157239914
5.00e-5   00006336*  96.00 | 0.698  0.100   | 0.019   | 3027.517594575882
5.00e-5   00006534*  99.00 | 0.705  0.103   | 0.019   | 3116.903386116028
5.00e-5   00006732* 102.00 | 0.718  0.100   | 0.018   | 3206.3653831481934
5.00e-5   00006930* 105.00 | 0.720  0.099   | 0.018   | 3295.763522863388
5.00e-5   00007128* 108.00 | 0.720  0.101   | 0.016   | 3385.294955253601
5.00e-5   00007326* 111.00 | 0.720  0.099   | 0.016   | 3474.8402128219604
5.00e-5   00007524* 114.00 | 0.730  0.099   | 0.017   | 3564.2625410556793
5.00e-5   00007722* 117.00 | 0.730  0.096   | 0.016   | 3653.68417263031
5.00e-5   00007920* 120.00 | 0.725  0.105   | 0.015   | 3743.178738117218
5.00e-5   00008118* 123.00 | 0.723  0.103   | 0.016   | 3833.0885529518127
5.00e-5   00008316* 126.00 | 0.725  0.098   | 0.015   | 3924.8953177928925
5.00e-5   00008514* 129.00 | 0.730  0.103   | 0.015   | 4017.752989292145
5.00e-5   00008712* 132.00 | 0.729  0.104   | 0.014   | 4109.193346738815
5.00e-5   00008910* 135.00 | 0.726  0.102   | 0.015   | 4203.284717798233

